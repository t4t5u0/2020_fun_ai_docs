{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "\n",
    "## 用語解説\n",
    "\n",
    "GAN Generative Adversarial Network 敵対的生成ネットワーク "
   ]
  },
  {
   "source": [
    "今日使うデータセット https://www.robots.ox.ac.uk/~vgg/data/flowers/102/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "torch\n",
    "torchvision\n",
    "tensorboard\n",
    "tqdm\n",
    "\n",
    "必要そうなライブラリ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/bin/bash: conda: コマンドが見つかりません\n",
      "torch==1.6.0\n",
      "torchaudio==0.6.0\n",
      "torchvision==0.7.0\n"
     ]
    }
   ],
   "source": [
    "# torchがあるか確認\n",
    "!(conda list || pip freeze) | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# データローダの個数\n",
    "# workers = 2\n",
    "workers = 16\n",
    "\n",
    "# バッチサイズ\n",
    "# batch_size = 128\n",
    "batch_size = 512\n",
    "\n",
    "# 画像のサイズ(リサイズ後)\n",
    "image_size = 64\n",
    "\n",
    "# カラーチャンネル\n",
    "nc = 3\n",
    "\n",
    "# 潜在ベクトルの大きさ (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# ジェネレーターのフィーチャーマップの大きさ\n",
    "ngf = 64\n",
    "\n",
    "# ディスクリミネーターのフィーチャーマップの大きさ\n",
    "ndf = 64\n",
    "\n",
    "# トレーニングエポックの大きさ\n",
    "num_epochs = 5\n",
    "\n",
    "# オプティマイザの学習率\n",
    "lr = 0.0002\n",
    "\n",
    "# Adamのハイパーパラメータ\n",
    "beta1 = 0.5\n",
    "\n",
    "# GPUの個数. 0ならCPU\n",
    "ngpu = 1\n",
    "\n",
    "#ロス確認用のサマリーライターを指定\n",
    "time = datetime.now()\n",
    "param_path = f'{Path.cwd()}/param/{time.year}{time.month:02}{time.day:02}{time.hour:02}{time.minute:02}'\n",
    "writer = SummaryWriter(param_path)\n",
    "\n",
    "# デバイス GPUとCPUの切り替え\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相対パスで記述\n",
    "img_folder = Path.cwd() / \"dataset\"\n",
    "\n",
    "# もし動かなかったら下みたいに絶対パスにしてください\n",
    "# img_folder = \"/home/t4t5u0/Develop/2020_fun_ai_docs/05/dataset\"\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    img_folder,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    ")\n",
    "\n",
    "# データローダー\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みを初期化するメソッド\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 入力はz\n",
    "            nn.ConvTranspose2d(in_channels=nz, out_channels=ngf*8,\n",
    "                               kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=ngf*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # テンソルのサイズ (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # テンソルのサイズ　(ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # テンソルのサイズ (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # テンソルのサイズ　(ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # テンソルのサイズ (nc) x 64 x 64\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generator(\n  (main): Sequential(\n    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): ReLU(inplace=True)\n    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (13): Tanh()\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "# ジェネレーターをインスタンス化\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "if (device.type == \"cuda\") and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "netG.apply(weights_init)\n",
    "print(netG) # 構造確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # 入力 (nc) * 64 * 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Discriminator(\n  (main): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (12): Sigmoid()\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "netD = Discriminator(ngpu).to(device)\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr,\n",
    "                        betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr,\n",
    "                        betas=(beta1, 0.999), weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Training Loop ...\n"
     ]
    }
   ],
   "source": [
    "print('Starting Training Loop ...')\n",
    "\n",
    "\n",
    "def train_GAN():\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    iters = 0\n",
    "    # for data, _ in tqdm(dataloader):\n",
    "    for data in tqdm(dataloader):\n",
    "        real_image = data[0].to(device)\n",
    "        sample_size = real_image.size(0)\n",
    "        # print(f'{sample_size=}')\n",
    "\n",
    "        netD.zero_grad()\n",
    "        # print(real_image.size())\n",
    "        label = torch.full((sample_size,), real_label,\n",
    "                           dtype=torch.float, device=device)\n",
    "        # print(f'{label=}')\n",
    "        output = netD(real_image).view(-1)\n",
    "        # print(f'{output.size()=}')\n",
    "\n",
    "        errD_real = criterion(output, label)\n",
    "\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        noise = torch.randn(sample_size, nz, 1, 1, device=device)\n",
    "\n",
    "        fake_image = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "\n",
    "        output = netD(fake_image.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        optimizerD.step()\n",
    "\n",
    "        ########################################\n",
    "\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "\n",
    "        output = netD(fake_image).view(-1)\n",
    "\n",
    "        errG = criterion(output, label)\n",
    "\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        optimizerG.step()\n",
    "        G_losses.append(errG.item())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            pass\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalars('loss', {\n",
    "                'D': D_losses[-1], 'G': G_losses[-1]\n",
    "            }, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    # train_dcgan(g, d, opt_g, opt_d, img_loader, writer)\n",
    "    train_GAN()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # パラメータの保存\n",
    "        torch.save(\n",
    "            netG.state_dict(),\n",
    "            f\"{param_path}/g_{epoch:04d}.prm\",\n",
    "            pickle_protocol=4\n",
    "        )\n",
    "        torch.save(\n",
    "            netD.state_dict(),\n",
    "            f\"{param_path}/d_{epoch:04d}.prm\",\n",
    "            pickle_protocol=4\n",
    "        )\n",
    "        generated_img = netG(fixed_noise)\n",
    "        # generated_img = g(fixed_z)\n",
    "        save_image(generated_img,\n",
    "                   f\"{param_path}/{epoch:04d}.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = ImageFolder(\n",
    "    \"/home/t4t5u0/Develop/2020_fun_ai_docs/05/dataset/\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(80),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor()  \n",
    "    ])\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "img_loader = DataLoader(img_data, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=True,\n",
    "                        num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習 パラメータを固定して，推論用の関数を作りなさい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間が足りませんでした\n",
    "def prediction(net, device):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}