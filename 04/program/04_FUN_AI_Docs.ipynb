{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "***\n",
    "\n",
    "## 概要  \n",
    "人間の視覚の仕組みを取り入れ成功したモデルである。現在も広く使われており、その応用範囲はとても広い。画像認識、クラス分類、など画像が絡むタスクはだいたいCNNを用いて解決される. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用語説明  \n",
    "***\n",
    "### CNN\n",
    "\n",
    "畳込み層を用いるニューラルネットワークのこと。\n",
    "\n",
    "### 画像\n",
    "\n",
    "デジタル画像には、カラー画像とモノクロ(グレースケール)画像の二種類がある。カラー画像はRGBでピクセルを制御している。モノクロ画像は0~255の値で離散化して持つ\n",
    "\n",
    "### 畳込み演算\n",
    "画像など(一般にtensor)に対して、各要素ごとにフィルタを積和演算する演算のこと。以下の用語説明や、理論解説でも取り扱う。\n",
    "\n",
    "![画像]()\n",
    "\n",
    "### 畳込み層\n",
    "畳込み演算を行う層を畳込み層と呼ぶ。英語ではConvolution Layer\n",
    "\n",
    "### 局所受容野、カーネル、フィルター\n",
    "\n",
    "説明する人の出身領域で言葉が変わってくるが本質的には同じものを指す。神経科学系なら局所受容野、画像系ならフィルター、その他はカーネルと呼んでいる人が多い気がする。今後、この資料ではフィルタでと呼ぶ。\n",
    "\n",
    "### パディング\n",
    "\n",
    "畳込みを行うと、tensorの大きさが小さくなるから、大きさを調整するために0などで画像の周囲を埋める\n",
    "\n",
    "### ストライド\n",
    "\n",
    "フィルタをどれだけ動かすか。通常は1\n",
    "\n",
    "### 重み共有\n",
    "\n",
    "### プーリング\n",
    "\n",
    "図のような演算をプーリング(max pooling)という。\n",
    "\n",
    "### プーリング層\n",
    "\n",
    "プーリングを行う層をプーリング層という。この層を挟むことによって、フィルターの感度が鈍くなることになる。その結果、位置ずれに対する頑健性があがると言われている。一方で、特徴が失われるという否定的な意見もある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理論解説\n",
    "***\n",
    "畳み込み演算とは、w h の大きさの画像に対してある画素$u_{ij}$に対して以下の操作を行うことを言う。\n",
    "\n",
    "\n",
    "$$\n",
    "u_{ij}=\\sum_{p=0}^{H-1}\\sum_{q=0}^{W-1}\\,\\it{x}_{i+p\\, j+q}\\,h_{pq}\\hspace{2em}\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装解説\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNの実装。MNISTの分類をする\n",
    "# 必要ライブラリのインポート\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレインデータを作成する\n",
    "# そのままだとPIL(Python Image Library)という独自の形式で画像を扱ってしまうから\n",
    "# transforms.ToTesnor() で PyTorch で扱いやすい Tensorに変換する\n",
    "# すでにダウンロードしている場合は、download=false に変更する\n",
    "mnist_train = MNIST(\"./Dataset/04/MNIST\",\n",
    "                   train=True, \n",
    "                   download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "\n",
    "# 同じくテストデータを作成する\n",
    "# こちらはtrain=falseになっている\n",
    "mnist_test = MNIST(\"./Dataset/04/MNIST\",\n",
    "                  train=False, \n",
    "                  download=True,\n",
    "                  transform=transforms.ToTensor())\n",
    "\n",
    "# バッチサイズが128のDataLoaderを作成する\n",
    "# バッチサイズを変更すると一回の学習で使うデータの量が変わる。メモリと相談する\n",
    "# 実際にネットワークに渡すのはこっち\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(dataset=mnist_train,\n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=mnist_test,\n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (N, C, H, W) 形式のTensorを(N, C*H*W) に引き伸ばす\n",
    "# 畳込み層の出力をMLPに渡す際に用いる\n",
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)\n",
    "\n",
    "# まずは畳み込み層を実装する\n",
    "# 今回は2層のCNN\n",
    "conv_net = nn.Sequential(\n",
    "    # 畳み込み\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "    # プーリング\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    # 活性化\n",
    "    nn.ReLU(),\n",
    "    # バッチノーマライゼーション(正規化)\n",
    "    nn.BatchNorm2d(num_features=32),\n",
    "    # ドロップアウト\n",
    "    nn.Dropout2d(p=0.25),\n",
    "    \n",
    "    nn.Conv2d(32, 64, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout2d(0.25),\n",
    "    \n",
    "    FlattenLayer()\n",
    ")\n",
    "\n",
    "# ダミーの画像を用意し、出力サイズを確認する\n",
    "test_input = torch.ones(1, 1, 28, 28)\n",
    "conv_output_size = conv_net(test_input).size()[-1]\n",
    "\n",
    "# 全結合層を用意する\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(in_features=conv_output_size, out_features=200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(num_features=200),\n",
    "    nn.Dropout(p=0.25),\n",
    "    nn.Linear(in_features=200, out_features=10)\n",
    ")\n",
    "\n",
    "# 畳み込み層と全結合層を1つにまとめる\n",
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    mlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用の関数\n",
    "def eval_net(net, data_loader, device = 'cpu'):\n",
    "    # DropputやBatchNorm を無効化する(評価時には必要ないから))\n",
    "    net.eval()\n",
    "\n",
    "    # 表示用の配列\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = torch.max(net(x), 1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        \n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    \n",
    "    acc = (ys == ypreds).float().sum() / len (ys)\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "# 訓練用の関数\n",
    "def train_net(net, train_loader, test_loader,\n",
    "             #optimizer = optim.Adam,\n",
    "             loss_func = nn.CrossEntropyLoss(),\n",
    "             n_iter = 10, device = 'cpu'):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        \n",
    "        for i, (xx, yy) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            # 勾配を初期化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = torch.max(h, 1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        \n",
    "        train_acc.append(n_acc / n)\n",
    "        \n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        \n",
    "        #学習結果をコンソールに表示\n",
    "        print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if Torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:学習結果を保存する\n",
    "     保存した学習結果を読み込んで推論\n",
    "     推論に用いた画像とラベルを表示する\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習問題"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37564bitpytorchcondac1588a0183c145a7ad887ad140edf980"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}