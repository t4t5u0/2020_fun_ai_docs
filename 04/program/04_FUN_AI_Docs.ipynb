{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "***\n",
    "\n",
    "## 概要  \n",
    "人間の視覚の仕組みを取り入れ成功したモデルである。現在も広く使われており、その応用範囲はとても広い。画像認識、クラス分類、など画像が絡むタスクはだいたいCNNを用いて解決される. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用語説明  \n",
    "***\n",
    "### CNN\n",
    "\n",
    "畳込み層を用いるニューラルネットワークのこと。  \n",
    "一般的には、\n",
    "- 畳み込み演算 (必須)\n",
    "- プーリング\n",
    "- 活性化関数(必須)　ReLUなど\n",
    "- バッチノーマライゼーション\n",
    "の4要素を繰り返すことで行う。\n",
    "\n",
    "### 画像\n",
    "\n",
    "デジタル画像には、カラー画像とモノクロ(グレースケール)画像の二種類がある。カラー画像はRGBでピクセルを制御している。モノクロ画像は0~255の値で離散化して持つ\n",
    "\n",
    "### 畳込み演算\n",
    "画像など(一般にtensor)に対して、各要素ごとにフィルタを積和演算する演算のこと。以下の用語説明や、理論解説でも取り扱う。\n",
    "\n",
    "![画像](../image/01.gif)\n",
    "\n",
    "### 畳込み層\n",
    "畳込み演算を行う層を畳込み層と呼ぶ。英語ではConvolution Layer\n",
    "\n",
    "### 局所受容野、カーネル、フィルター\n",
    "\n",
    "説明する人の出身領域で言葉が変わってくるが本質的には同じものを指す。神経科学系なら局所受容野、画像系ならフィルター、その他はカーネルと呼んでいる人が多い気がする。今後、この資料ではフィルタでと呼ぶ。\n",
    "\n",
    "### パディング\n",
    "\n",
    "畳込みを行うと、tensorの大きさが小さくなるから、大きさを調整するために0などで画像の周囲を埋めること\n",
    "\n",
    "### ストライド\n",
    "\n",
    "フィルタをどれだけ動かすか。上の例では1\n",
    "\n",
    "### 重み共有\n",
    "\n",
    "### プーリング\n",
    "\n",
    "図のような演算をプーリング(max pooling)という。  \n",
    "![](../image/02.jpg)\n",
    "\n",
    "### プーリング層\n",
    "\n",
    "プーリングを行う層をプーリング層という。この層を挟むことによって、フィルターの感度が鈍くなることになる。その結果、位置ずれに対する頑健性(局所不変性)があがると言われている。一方で、特徴が失われるという否定的な意見もある。\n",
    "\n",
    "### バッチノーマライゼーション\n",
    "ミニバッチ内の全データを分散1、平均0に正規化する処理(正規分布に従うようにするわけではない)。強い正則化効果がある。ミニバッチとは、一回に処理するデータのまとまりのこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理論解説\n",
    "***\n",
    "畳み込み演算とは、$e_w \\times e_w$ の大きさのフィルターを用いて画素$x_{ij}$に対して以下の操作を行うことを言う。  \n",
    "e はフィルタ。u は出力\n",
    "\n",
    "$$\n",
    "u_{ij}=\\sum_{p=0}^{e_h-1}\\sum_{q=0}^{e_w-1}\\,\\it{x}_{(i+p)(j+q)}\\,e_{pq}\\hspace{2em}\\tag{1}\n",
    "$$\n",
    "\n",
    "ネットワークパラメータを\n",
    "- フィルターの幅と高さ　$e_w, e_h$\n",
    "- ストライド $s$ フィルターの移動距離を表す\n",
    "- パディング $p$ 画像の周囲を0で埋める個数\n",
    "- $k$ フィルターが適用される個数\n",
    "\n",
    "とすると\n",
    "\n",
    "畳み込みを行った後の画像のサイズは、\n",
    "$$\n",
    "幅: w_{out} = \\lceil \\frac{w_{in} - e_w + 2p }{s} \\rceil + 1 \\\\\n",
    "高さ: h_{out} = \\lceil \\frac{h_{in} - e_h + 2p }{s} \\rceil + 1 \\\\\n",
    "奥行き: d_{out} = k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装解説\n",
    "***\n",
    "以下はAlexNetというCNNモデルのアーキテクチャである。これは一般的なCNNを用いたクラス分類の構成と言って差し支えないだろう\n",
    "\n",
    "![](../image/04.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir ../param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNの実装。MNISTの分類をする\n",
    "# 必要ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを加工。csvファイルから画像の塊に変換する\n",
    "\n",
    "train = pd.read_csv(r\"../input/digit-recognizer/train.csv\", dtype=np.float32)\n",
    "\n",
    "# split data into features(pixels) and labels(numbers from 0 to 9)\n",
    "# ラベル(0-9)\n",
    "targets_numpy = train.label.values\n",
    "# 画像データセット (784x1に伸ばされている)\n",
    "features_numpy = train.loc[:, train.columns != \"label\"].values/255\n",
    "\n",
    "# 訓練用とテスト用にデータセットを分割\n",
    "features_train, features_test, targets_train, targets_test = train_test_split(\n",
    "    features_numpy, targets_numpy, test_size=0.2, random_state=42)\n",
    "\n",
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "# NumPy配列からTensorに変換\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "featuresTrain = featuresTrain.reshape([-1 ,1 ,28, 28])\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "# NumPy配列からTensorに変換\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "featuresTest = featuresTest.reshape([-1, 1, 28, 28])\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "# バッチサイズとエポック数を決定\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "# 画像とラベルの組をデータセット に変換\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "# ミニバッチ用のデータローダーを作成\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# visualize one of the images in data set\n",
    "# 画像を可視化\n",
    "plt.imshow(features_numpy[10].reshape(28, 28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnetedLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            # nn.Conv2d(1, 32, 5),\n",
    "            # nn.MaxPool2d(2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            # nn.Conv2d(32, 64, 5),\n",
    "            # nn.MaxPool2d(2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            self.cnn,\n",
    "            FullyConnetedLayer(),\n",
    "            self.mlp\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用の関数\n",
    "def eval_net(net, data_loader, device = 'cpu'):\n",
    "    # DropputやBatchNorm を無効化する(評価時には必要ないから))\n",
    "    net.eval()\n",
    "\n",
    "    # 表示用の配列\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = torch.max(net(x), 1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        \n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    \n",
    "    acc = (ys == ypreds).float().sum() / len (ys)\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "# 訓練用の関数\n",
    "def train_net(net, train_loader, test_loader,\n",
    "             #optimizer = optim.Adam,\n",
    "             loss_fn = nn.CrossEntropyLoss(),\n",
    "             n_iter = 10, device = 'cpu'):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        \n",
    "        for i, (xx, yy) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            # 勾配を初期化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = torch.max(h, 1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        \n",
    "        train_acc.append(n_acc / n)\n",
    "        \n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        \n",
    "        #学習結果をコンソールに表示\n",
    "        print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), r'../param/parameter.prm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証用データセットを作成\n",
    "test = pd.read_csv(r\"../input/digit-recognizer/test.csv\", dtype=np.float32)\n",
    "\n",
    "# データを正規化し、Tensorを作る\n",
    "features_test = test.values/255\n",
    "features_test = torch.from_numpy(features_test)\n",
    "features_test = features_test.reshape([-1, 1, 28, 28])\n",
    "test = TensorDataset(features_test)\n",
    "\n",
    "# データローダを作成\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論用の関数\n",
    "def prediction(data_loader, device='cpu'):\n",
    "    net.load_state_dict(torch.load(r'../param/parameter.prm'))\n",
    "    net.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "\n",
    "    for i, images in enumerate(data_loader):\n",
    "        # print(images[0].size())\n",
    "        images = images[0].to(device)\n",
    "        output = net(images)\n",
    "        _, pred = output.cpu().data.max(1, keepdim=True)\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論を行う\n",
    "test_pred = prediction(test_loader, device=device)\n",
    "\n",
    "# データの整形\n",
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test)+1)[:,None],\n",
    "    test_pred.numpy()], columns=['ImageId', 'Label'])\n",
    "\n",
    "# 出力\n",
    "out_df.head()\n",
    "out_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習問題\n",
    "- 以下の畳み込み演算を手計算する\n",
    "\n",
    "![](../image/03.jpg)\n",
    "\n",
    "- self.cnn を完成させる\n",
    "- 学習結果をkaggleにsubmitする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37564bitpytorchcondac1588a0183c145a7ad887ad140edf980"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}