{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "***\n",
    "\n",
    "## 概要  \n",
    "人間の視覚の仕組みを取り入れ成功したモデルである。現在も広く使われており、その応用範囲はとても広い。画像認識、クラス分類、など画像が絡むタスクはだいたいCNNを用いて解決される. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用語説明  \n",
    "***\n",
    "### CNN\n",
    "\n",
    "畳込み層を用いるニューラルネットワークのこと。\n",
    "\n",
    "### 画像\n",
    "\n",
    "デジタル画像には、カラー画像とモノクロ(グレースケール)画像の二種類がある。カラー画像はRGBでピクセルを制御している。モノクロ画像は0~255の値で離散化して持つ\n",
    "\n",
    "### 畳込み演算\n",
    "画像など(一般にtensor)に対して、各要素ごとにフィルタを積和演算する演算のこと。以下の用語説明や、理論解説でも取り扱う。\n",
    "\n",
    "![画像]()\n",
    "\n",
    "### 畳込み層\n",
    "畳込み演算を行う層を畳込み層と呼ぶ。英語ではConvolution Layer\n",
    "\n",
    "### 局所受容野、カーネル、フィルター\n",
    "\n",
    "説明する人の出身領域で言葉が変わってくるが本質的には同じものを指す。神経科学系なら局所受容野、画像系ならフィルター、その他はカーネルと呼んでいる人が多い気がする。今後、この資料ではフィルタでと呼ぶ。\n",
    "\n",
    "### パディング\n",
    "\n",
    "畳込みを行うと、tensorの大きさが小さくなるから、大きさを調整するために0などで画像の周囲を埋める\n",
    "\n",
    "### ストライド\n",
    "\n",
    "フィルタをどれだけ動かすか。通常は1\n",
    "\n",
    "### 重み共有\n",
    "\n",
    "### プーリング\n",
    "\n",
    "図のような演算をプーリング(max pooling)という。\n",
    "\n",
    "### プーリング層\n",
    "\n",
    "プーリングを行う層をプーリング層という。この層を挟むことによって、フィルターの感度が鈍くなることになる。その結果、位置ずれに対する頑健性があがると言われている。一方で、特徴が失われるという否定的な意見もある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理論解説\n",
    "***\n",
    "畳み込み演算とは、w h の大きさの画像に対してある画素$u_{ij}$に対して以下の操作を行うことを言う。\n",
    "\n",
    "\n",
    "$$\n",
    "u_{ij}=\\sum_{p=0}^{H-1}\\sum_{q=0}^{W-1}\\,\\it{x}_{i+p\\, j+q}\\,h_{pq}\\hspace{2em}\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装解説\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNの実装。MNISTの分類をする\n",
    "# 必要ライブラリのインポート\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0it [00:00, ?it/s]Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n9920512it [00:02, 4200323.45it/s]\nExtracting ./Dataset/04/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw\n0it [00:00, ?it/s]Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n32768it [00:00, 58542.93it/s]\n0it [00:00, ?it/s]Extracting ./Dataset/04/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n1654784it [00:01, 1145159.83it/s]\n0it [00:00, ?it/s]Extracting ./Dataset/04/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n8192it [00:00, 20479.29it/s]Extracting ./Dataset/04/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./Dataset/04/MNIST/MNIST/raw\nProcessing...\nDone!\n\n"
    }
   ],
   "source": [
    "# # トレインデータを作成する\n",
    "# # そのままだとPIL(Python Image Library)という独自の形式で画像を扱ってしまうから\n",
    "# # transforms.ToTesnor() で PyTorch で扱いやすい Tensorに変換する\n",
    "# # すでにダウンロードしている場合は、download=false に変更する\n",
    "# mnist_train = MNIST(\"./Dataset/04/MNIST\",\n",
    "#                    train=True, \n",
    "#                    download=True,\n",
    "#                    transform=transforms.ToTensor())\n",
    "\n",
    "# # 同じくテストデータを作成する\n",
    "# # こちらはtrain=falseになっている\n",
    "# mnist_test = MNIST(\"./Dataset/04/MNIST\",\n",
    "#                   train=False, \n",
    "#                   download=True,\n",
    "#                   transform=transforms.ToTensor())\n",
    "\n",
    "# # バッチサイズが128のDataLoaderを作成する\n",
    "# # バッチサイズを変更すると一回の学習で使うデータの量が変わる。メモリと相談する\n",
    "# # 実際にネットワークに渡すのはこっち\n",
    "# batch_size = 128\n",
    "\n",
    "# train_loader = DataLoader(dataset=mnist_train,\n",
    "#                          batch_size=batch_size, \n",
    "#                          shuffle=True)\n",
    "\n",
    "# test_loader = DataLoader(dataset=mnist_test,\n",
    "#                         batch_size=batch_size, \n",
    "#                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (N, C, H, W) 形式のTensorを(N, C*H*W) に引き伸ばす\n",
    "# # 畳込み層の出力をMLPに渡す際に用いる\n",
    "# class FlattenLayer(nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         sizes = x.size()\n",
    "#         return x.view(sizes[0], -1)\n",
    "\n",
    "# # まずは畳み込み層を実装する\n",
    "# # 今回は2層のCNN\n",
    "# conv_net = nn.Sequential(\n",
    "#     # 畳み込み\n",
    "#     nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "#     # プーリング\n",
    "#     nn.MaxPool2d(kernel_size=2),\n",
    "#     # 活性化\n",
    "#     nn.ReLU(),\n",
    "#     # バッチノーマライゼーション(正規化)\n",
    "#     nn.BatchNorm2d(num_features=32),\n",
    "#     # ドロップアウト\n",
    "#     nn.Dropout2d(p=0.25),\n",
    "    \n",
    "#     nn.Conv2d(32, 64, 5),\n",
    "#     nn.MaxPool2d(2),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm2d(64),\n",
    "#     nn.Dropout2d(0.25),\n",
    "    \n",
    "#     FlattenLayer()\n",
    "# )\n",
    "\n",
    "# # ダミーの画像を用意し、出力サイズを確認する\n",
    "# test_input = torch.ones(1, 1, 28, 28)\n",
    "# conv_output_size = conv_net(test_input).size()[-1]\n",
    "\n",
    "# # 全結合層を用意する\n",
    "# mlp = nn.Sequential(\n",
    "#     nn.Linear(in_features=conv_output_size, out_features=200),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(num_features=200),\n",
    "#     nn.Dropout(p=0.25),\n",
    "#     nn.Linear(in_features=200, out_features=10)\n",
    "# )\n",
    "\n",
    "# # 畳み込み層と全結合層を1つにまとめる\n",
    "# net = nn.Sequential(\n",
    "#     conv_net,\n",
    "#     mlp\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0], -1)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            self.cnn,\n",
    "            FlattenLayer(),\n",
    "            self.mlp\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用の関数\n",
    "def eval_net(net, data_loader, device = 'cpu'):\n",
    "    # DropputやBatchNorm を無効化する(評価時には必要ないから))\n",
    "    net.eval()\n",
    "\n",
    "    # 表示用の配列\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = torch.max(net(x), 1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        \n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    \n",
    "    acc = (ys == ypreds).float().sum() / len (ys)\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "# 訓練用の関数\n",
    "def train_net(net, train_loader, test_loader,\n",
    "             #optimizer = optim.Adam,\n",
    "             loss_fn = nn.CrossEntropyLoss(),\n",
    "             n_iter = 10, device = 'cpu'):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        \n",
    "        for i, (xx, yy) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            # 勾配を初期化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = torch.max(h, 1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        \n",
    "        train_acc.append(n_acc / n)\n",
    "        \n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        \n",
    "        #学習結果をコンソールに表示\n",
    "        print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 469/469 [00:04<00:00, 98.24it/s]\n0 1.5064653372153258 0.9662833333333334 0.9853999614715576\n100%|██████████| 469/469 [00:04<00:00, 98.67it/s]\n1 1.476769709943706 0.9887333333333334 0.9870999455451965\n100%|██████████| 469/469 [00:04<00:00, 99.79it/s]\n2 1.4743878428752606 0.9905166666666667 0.9871999621391296\n100%|██████████| 469/469 [00:04<00:00, 102.30it/s]\n3 1.4729317477625659 0.9917333333333334 0.9886999726295471\n100%|██████████| 469/469 [00:04<00:00, 102.61it/s]\n4 1.4714409703882332 0.99325 0.9914000034332275\n100%|██████████| 469/469 [00:04<00:00, 102.22it/s]\n5 1.4707105254006183 0.99395 0.9892999529838562\n100%|██████████| 469/469 [00:04<00:00, 102.65it/s]\n6 1.470138143779885 0.9943 0.9905999898910522\n100%|██████████| 469/469 [00:04<00:00, 102.96it/s]\n7 1.4699896125711946 0.99445 0.9923999905586243\n100%|██████████| 469/469 [00:04<00:00, 102.81it/s]\n8 1.4692749910884433 0.9951333333333333 0.9896000027656555\n100%|██████████| 469/469 [00:04<00:00, 104.19it/s]\n9 1.4691147450198474 0.99535 0.9917999505996704\n100%|██████████| 469/469 [00:04<00:00, 105.45it/s]\n10 1.4691455621495206 0.9952166666666666 0.991599977016449\n100%|██████████| 469/469 [00:04<00:00, 99.57it/s]\n11 1.4686924550268385 0.9956666666666667 0.9908999800682068\n100%|██████████| 469/469 [00:04<00:00, 103.24it/s]\n12 1.4683677482808757 0.99595 0.9896999597549438\n100%|██████████| 469/469 [00:04<00:00, 104.18it/s]\n13 1.4685747666746123 0.9957333333333334 0.991599977016449\n100%|██████████| 469/469 [00:04<00:00, 100.48it/s]\n14 1.4684417922782083 0.9958666666666667 0.9921999573707581\n100%|██████████| 469/469 [00:04<00:00, 101.48it/s]\n15 1.4677452175026267 0.99655 0.9918999671936035\n100%|██████████| 469/469 [00:04<00:00, 102.43it/s]\n16 1.4685366036545517 0.9958833333333333 0.9918999671936035\n100%|██████████| 469/469 [00:04<00:00, 101.80it/s]\n17 1.4679405368291414 0.9963166666666666 0.9916999936103821\n100%|██████████| 469/469 [00:04<00:00, 102.53it/s]\n18 1.467753012975057 0.9965333333333334 0.9926999807357788\n100%|██████████| 469/469 [00:04<00:00, 103.10it/s]\n19 1.4672700963978074 0.99705 0.9928999543190002\n"
    }
   ],
   "source": [
    "net = CNN()\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), r'../param/parameter.prm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証用データセットを作成\n",
    "test = pd.read_csv(r\"../../03/input/digit-recognizer/test.csv\", dtype=np.float32)\n",
    "\n",
    "# データを正規化し、Tensorを作る\n",
    "features_test = test.values/255\n",
    "features_test = torch.from_numpy(features_test)\n",
    "features_test = features_test.reshape([-1, 28, 28, 1])\n",
    "test = TensorDataset(features_test)\n",
    "\n",
    "# データローダを作成\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論用の関数\n",
    "def prediction(data_loader, device='cpu'):\n",
    "    net.load_state_dict(torch.load(r'../param/parameter.prm'))\n",
    "    net.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "\n",
    "    for i, images in enumerate(data_loader):\n",
    "        # print(images[0].size())\n",
    "        images = images[0].to(device)\n",
    "        output = net(images)\n",
    "        _, pred = output.cpu().data.max(1, keepdim=True)\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 32 1 5 5, expected input[128, 28, 28, 1] to have 1 channels, but got 28 channels instead",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fc2c4dfcfb28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 推論を行う\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# データの整形\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m out_df = pd.DataFrame(np.c_[np.arange(1, len(test)+1)[:,None],\n",
      "\u001b[0;32m<ipython-input-27-8d688e32df8a>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(data_loader, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# print(images[0].size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-287017b5545a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         )\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 32 1 5 5, expected input[128, 28, 28, 1] to have 1 channels, but got 28 channels instead"
     ]
    }
   ],
   "source": [
    "# 推論を行う\n",
    "test_pred = prediction(test_loader, device=device)\n",
    "\n",
    "# データの整形\n",
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test)+1)[:,None],\n",
    "    test_pred.numpy()], columns=['ImageId', 'Label'])\n",
    "\n",
    "# 出力\n",
    "out_df.head()\n",
    "out_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- [x] 学習結果を保存する\n",
    "- [x] 保存した学習結果を読み込んで推論\n",
    "- [x] 推論に用いた画像とラベルを表示する\n",
    "- [ ] 32\\*32 -> 28\\*28 に変更する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "演習問題"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37564bitpytorchcondac1588a0183c145a7ad887ad140edf980"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}